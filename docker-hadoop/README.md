# ğŸ˜ Proyecto Hadoop con Docker - AnÃ¡lisis de E-commerce

Proyecto de Big Data que implementa un cluster de Hadoop usando Docker para analizar datos de comportamiento de usuarios en un sitio de e-commerce mediante MapReduce con Python.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto configura un entorno completo de Hadoop distribuido usando contenedores Docker y realiza anÃ¡lisis de datos sobre un dataset de e-commerce (2019-Oct.csv) que contiene millones de eventos de usuarios como vistas de productos, adiciones al carrito y compras.

### AnÃ¡lisis Implementados

1. **Top 10 Productos MÃ¡s Vistos**: Identifica los productos con mayor nÃºmero de vistas
2. **Monto Total por Cliente**: Calcula cuÃ¡nto dinero gastÃ³ cada cliente en productos agregados al carrito
3. **ArtÃ­culos por Semana**: Cuenta cuÃ¡ntos artÃ­culos fueron agregados al carrito cada semana

## ğŸ—ï¸ Arquitectura del Cluster

El cluster de Hadoop estÃ¡ compuesto por los siguientes servicios:

- **NameNode** (puerto 9870): Nodo maestro que gestiona el sistema de archivos HDFS
- **DataNode**: Nodo que almacena los datos distribuidos
- **ResourceManager** (puerto 8088): Gestiona los recursos del cluster YARN
- **NodeManager**: Ejecuta las tareas de MapReduce
- **HistoryServer**: Mantiene histÃ³rico de jobs ejecutados

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Docker Desktop instalado
- Git
- Al menos 8GB de RAM disponible

### 1. Levantar el Cluster de Hadoop

```bash
cd docker-hadoop
docker-compose up -d
```

Verifica que todos los contenedores estÃ©n corriendo:
```bash
docker-compose ps
```

Accede a las interfaces web:
- **NameNode UI**: http://localhost:9870
- **ResourceManager UI**: http://localhost:8088

### 2. Preparar el Archivo de Datos

Necesitas el archivo `2019-Oct.csv` (dataset de e-commerce). Una vez que lo tengas, cÃ³pialo al contenedor:

```bash
docker cp 2019-Oct.csv namenode:/tmp/2019-Oct.csv
```

### 3. Subir Datos a HDFS

ConÃ©ctate al namenode:
```bash
docker exec -it namenode bash

Dentro del contenedor, sube el archivo a HDFS:
```bash
hadoop fs -put /tmp/2019-Oct.csv /tmp/2019-Oct.csv
```

Verifica que el archivo se subiÃ³ correctamente:
```bash
hadoop fs -ls /tmp/
hadoop fs -du -h /tmp/2019-Oct.csv
```

### 4. Ejecutar los Jobs de MapReduce

#### Copiar los scripts de Python al contenedor:
```bash
docker cp python-mapreduce namenode:/opt/hadoop-3.2.1/
```

#### Conectarse al namenode y dar permisos:
```bash
docker exec -it namenode bash
cd /opt/hadoop-3.2.1/python-mapreduce
chmod +x *.py
```

#### Ejecutar Job 1: Top 10 Productos MÃ¡s Vistos

```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files top10_mapper.py,top10_reducer.py \
  -mapper 'python3 top10_mapper.py' \
  -reducer 'python3 top10_reducer.py' \
  -input /tmp/2019-Oct.csv \
  -output /output/top10_productos
```

Ver resultados:
```bash
hadoop fs -cat /output/top10_productos/part-00000
```

#### Ejecutar Job 2: Monto Total por Cliente

```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files monto_mapper.py,monto_reducer.py \
  -mapper 'python3 monto_mapper.py' \
  -reducer 'python3 monto_reducer.py' \
  -input /tmp/2019-Oct.csv \
  -output /output/monto_cliente
```

Ver resultados (primeros 20):
```bash
hadoop fs -cat /output/monto_cliente/part-00000 | head -20
```

#### Ejecutar Job 3: ArtÃ­culos por Semana

```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files semana_mapper.py,semana_reducer.py \
  -mapper 'python3 semana_mapper.py' \
  -reducer 'python3 semana_reducer.py' \
  -input /tmp/2019-Oct.csv \
  -output /output/articulos_semana
```

Ver resultados:
```bash
hadoop fs -cat /output/articulos_semana/part-00000
```

## ğŸ“Š Estructura del Dataset

El archivo CSV contiene las siguientes columnas:

| Columna | DescripciÃ³n |
|---------|-------------|
| event_time | Timestamp del evento |
| event_type | Tipo: view, cart, purchase |
| product_id | ID Ãºnico del producto |
| category_id | ID de categorÃ­a |
| category_code | CÃ³digo de categorÃ­a |
| brand | Marca del producto |
| price | Precio del producto |
| user_id | ID del usuario |
| user_session | ID de sesiÃ³n |

## ğŸ”§ Comandos Ãštiles

### GestiÃ³n de HDFS

```bash
# Listar archivos en HDFS
hadoop fs -ls /

# Ver espacio usado
hadoop fs -df -h

# Eliminar directorios de output (para re-ejecutar jobs)
hadoop fs -rm -r /output/*

# Descargar resultados desde HDFS
hadoop fs -get /output/top10_productos/part-00000 resultado_top10.txt
```

### GestiÃ³n de Docker

```bash
# Ver logs de un contenedor
docker logs namenode

# Detener el cluster
docker-compose down

# Detener y eliminar volÃºmenes (Â¡cuidado, borra datos!)
docker-compose down -v

# Reiniciar un servicio especÃ­fico
docker-compose restart namenode
```

### Descargar Resultados a Windows

Desde fuera del contenedor:
```bash
docker cp namenode:/opt/hadoop-3.2.1/python-mapreduce/resultado_top10.txt ./
```

## ğŸ“ Estructura del Proyecto

```
docker-hadoop/
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n del cluster
â”œâ”€â”€ hadoop.env                  # Variables de entorno
â”œâ”€â”€ base/                       # Imagen base de Hadoop
â”œâ”€â”€ namenode/                   # ConfiguraciÃ³n del NameNode
â”œâ”€â”€ datanode/                   # ConfiguraciÃ³n del DataNode
â”œâ”€â”€ resourcemanager/            # ConfiguraciÃ³n del ResourceManager
â”œâ”€â”€ nodemanager/                # ConfiguraciÃ³n del NodeManager
â”œâ”€â”€ historyserver/              # ConfiguraciÃ³n del HistoryServer
â””â”€â”€ python-mapreduce/           # Scripts de MapReduce
    â”œâ”€â”€ top10_mapper.py         # Mapper: productos mÃ¡s vistos
    â”œâ”€â”€ top10_reducer.py        # Reducer: productos mÃ¡s vistos
    â”œâ”€â”€ monto_mapper.py         # Mapper: monto por cliente
    â”œâ”€â”€ monto_reducer.py        # Reducer: monto por cliente
    â”œâ”€â”€ semana_mapper.py        # Mapper: artÃ­culos por semana
    â”œâ”€â”€ semana_reducer.py       # Reducer: artÃ­culos por semana
    â”œâ”€â”€ run_all.sh              # Script para ejecutar todos los jobs
    â””â”€â”€ README.md               # DocumentaciÃ³n de MapReduce
```

## ğŸ Â¿CÃ³mo Funciona MapReduce con Python?

Hadoop Streaming permite ejecutar scripts Python como Mappers y Reducers:

1. **Mapper**: Lee datos lÃ­nea por lÃ­nea desde `stdin`, procesa y emite pares clave-valor a `stdout`
2. **Hadoop Shuffle & Sort**: Agrupa y ordena automÃ¡ticamente por clave
3. **Reducer**: Recibe datos agrupados, los procesa y emite resultados finales

### Ventajas de Python Streaming
- âœ… No requiere compilaciÃ³n
- âœ… CÃ³digo mÃ¡s simple y legible que Java
- âœ… FÃ¡cil de debuggear localmente
- âœ… Puedes usar cualquier librerÃ­a de Python

## ğŸ“ˆ Monitoreo

Mientras los jobs se ejecutan, puedes monitorearlos en:

- **NameNode UI** (http://localhost:9870): Estado del HDFS, bloques, nodos
- **ResourceManager UI** (http://localhost:8088): Jobs en ejecuciÃ³n, progreso, logs

## âš ï¸ SoluciÃ³n de Problemas

### El contenedor no inicia
```bash
docker-compose logs namenode
```

### Error: "Output directory already exists"
```bash
hadoop fs -rm -r /output/nombre_directorio
```

### Error: "Permission denied" en scripts Python
```bash
chmod +x *.py
```

### Ver logs de un job especÃ­fico
```bash
yarn logs -applicationId application_XXXXX_XXXX
```

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Hadoop](https://hadoop.apache.org/docs/current/)
- [Hadoop Streaming](https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html)
- [HDFS Commands Guide](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

## ğŸ‘¥ Autor

Nicolas Lester - Big Data Project 2025

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto para fines educativos.
