# ğŸ˜ Hadoop Big Data - AnÃ¡lisis de E-commerce con MapReduce

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **cluster Hadoop distribuido** utilizando Docker para analizar datos de comportamiento de usuarios en un e-commerce. A travÃ©s de **MapReduce con Python**, se procesan millones de eventos de compra para obtener insights de negocio.

El dataset utilizado contiene eventos de usuarios en una tienda online durante octubre de 2019, incluyendo:
- ğŸ” Visualizaciones de productos
- ğŸ›’ Productos aÃ±adidos al carrito
- ğŸ’³ Compras realizadas

### ğŸ¯ Objetivos del AnÃ¡lisis

1. **Top 10 Productos MÃ¡s Vistos** - Identificar los productos con mayor engagement
2. **Monto Total por Cliente** - Calcular el valor total de compras por usuario
3. **ArtÃ­culos en Carrito por Semana** - Analizar tendencias temporales de compra

---

## ğŸ—ï¸ Arquitectura del Cluster

El proyecto utiliza **Docker Compose** para desplegar un cluster Hadoop completo con los siguientes componentes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HADOOP CLUSTER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NameNode (puerto 9870)                                 â”‚
â”‚  - Gestiona el sistema de archivos HDFS                â”‚
â”‚  - Almacena metadata de todos los archivos             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DataNode                                               â”‚
â”‚  - Almacena los bloques de datos reales                â”‚
â”‚  - Se comunica con el NameNode                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ResourceManager (puerto 8088)                          â”‚
â”‚  - Gestiona recursos del cluster (CPU, memoria)        â”‚
â”‚  - Coordina la ejecuciÃ³n de jobs MapReduce             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NodeManager                                            â”‚
â”‚  - Ejecuta las tareas Map y Reduce                     â”‚
â”‚  - Monitorea recursos locales                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  HistoryServer                                          â”‚
â”‚  - Mantiene historial de jobs ejecutados               â”‚
â”‚  - Permite consultar logs de jobs completados          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Docker Desktop instalado
- MÃ­nimo 8GB RAM disponible
- 20GB de espacio en disco
- Dataset CSV (2019-Oct.csv o similar)

### 1ï¸âƒ£ Levantar el Cluster

```bash
# Clonar el repositorio
git clone https://github.com/Nicolas-Lester/hadoop.git
cd hadoop/docker-hadoop

# Iniciar todos los servicios
docker-compose up -d

# Verificar que todos los contenedores estÃ©n corriendo
docker-compose ps
```

**Servicios Disponibles:**
- ğŸŒ NameNode UI: http://localhost:9870
- ğŸ“Š ResourceManager UI: http://localhost:8088

### 2ï¸âƒ£ Preparar el Dataset

```bash
# Copiar el archivo CSV al contenedor NameNode
docker cp /ruta/a/tu/2019-Oct.csv namenode:/tmp/

# Conectarse al NameNode
docker exec -it namenode bash

# Crear directorio en HDFS
hadoop fs -mkdir -p /tmp

# Subir el archivo a HDFS
hadoop fs -put /tmp/2019-Oct.csv /tmp/

# Verificar que el archivo se subiÃ³ correctamente
hadoop fs -ls /tmp/
hadoop fs -tail /tmp/2019-Oct.csv
```

### 3ï¸âƒ£ Copiar Scripts de MapReduce

```bash
# Desde tu mÃ¡quina local (fuera del contenedor)
docker cp python-mapreduce namenode:/opt/hadoop-3.2.1/

# Entrar al contenedor
docker exec -it namenode bash

# Navegar al directorio y dar permisos
cd /opt/hadoop-3.2.1/python-mapreduce
chmod +x *.py *.sh
```

---

## ğŸ“Š AnÃ¡lisis con MapReduce

### ğŸ¥‡ Job 1: Top 10 Productos MÃ¡s Vistos

**Objetivo:** Identificar los productos con mÃ¡s visualizaciones para optimizar inventario y promociones.

**Formato del Dataset:**
```csv
event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
2019-10-01 00:00:00,view,1004767,2053013555631882655,electronics.smartphone,samsung,489.07,512345678,9eb...
```

**Ejecutar el Job:**
```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files top10_mapper.py,top10_reducer.py \
  -mapper top10_mapper.py \
  -reducer top10_reducer.py \
  -input /tmp/2019-Oct.csv \
  -output /output/python_top10_productos
```

**Ver Resultados:**
```bash
hadoop fs -cat /output/python_top10_productos/part-00000
```

**Salida Esperada:**
```
1004767    25000    # Product ID    # NÃºmero de views
5100500    18500
3902945    15200
...
```

---

### ğŸ’° Job 2: Monto Total por Cliente

**Objetivo:** Calcular el valor total de compras por cada cliente para segmentaciÃ³n y anÃ¡lisis de valor del cliente (CLV).

**Ejecutar el Job:**
```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files monto_mapper.py,monto_reducer.py \
  -mapper monto_mapper.py \
  -reducer monto_reducer.py \
  -input /tmp/2019-Oct.csv \
  -output /output/python_monto_cliente
```

**Ver Resultados (Top 20):**
```bash
hadoop fs -cat /output/python_monto_cliente/part-00000 | head -20
```

**Salida Esperada:**
```
541312140    350.75    # User ID    # Monto total ($)
554748717    1250.00
519107250    543.10
...
```

---

### ğŸ“… Job 3: ArtÃ­culos en Carrito por Semana

**Objetivo:** Analizar patrones temporales de comportamiento de compra para planificaciÃ³n de inventario y campaÃ±as.

**Ejecutar el Job:**
```bash
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -files semana_mapper.py,semana_reducer.py \
  -mapper semana_mapper.py \
  -reducer semana_reducer.py \
  -input /tmp/2019-Oct.csv \
  -output /output/python_articulos_semana
```

**Ver Resultados:**
```bash
hadoop fs -cat /output/python_articulos_semana/part-00000
```

**Salida Esperada:**
```
2019-W40    5000     # AÃ±o-Semana    # ArtÃ­culos en carrito
2019-W41    7500
2019-W42    8200
2019-W43    6800
```

---

## ğŸ”§ EjecuciÃ³n Automatizada

Para ejecutar los 3 anÃ¡lisis de forma secuencial:

```bash
cd /opt/hadoop-3.2.1/python-mapreduce
./run_all.sh
```

Este script:
1. Limpia outputs anteriores
2. Ejecuta los 3 jobs MapReduce
3. Muestra los resultados de cada uno
4. Guarda logs de ejecuciÃ³n

---

## ğŸ§ª Probar Localmente (Sin Hadoop)

Antes de ejecutar en Hadoop, puedes probar los scripts localmente:

```bash
# Job 1: Top 10 Productos
cat 2019-Oct.csv | ./top10_mapper.py | sort | ./top10_reducer.py

# Job 2: Monto por Cliente
cat 2019-Oct.csv | ./monto_mapper.py | sort | ./monto_reducer.py

# Job 3: ArtÃ­culos por Semana
cat 2019-Oct.csv | ./semana_mapper.py | sort | ./semana_reducer.py
```

Esto simula el flujo de MapReduce: Mapper â†’ Sort â†’ Reducer

---

## ğŸ“¥ Descargar Resultados

### Desde el Contenedor

```bash
# Dentro del NameNode
hadoop fs -get /output/python_top10_productos/part-00000 top10_resultados.txt
hadoop fs -get /output/python_monto_cliente/part-00000 monto_resultados.txt
hadoop fs -get /output/python_articulos_semana/part-00000 semana_resultados.txt
```

### A tu MÃ¡quina Local

```bash
# Desde Windows/Linux/Mac
docker cp namenode:/opt/hadoop-3.2.1/python-mapreduce/top10_resultados.txt ./resultados/
docker cp namenode:/opt/hadoop-3.2.1/python-mapreduce/monto_resultados.txt ./resultados/
docker cp namenode:/opt/hadoop-3.2.1/python-mapreduce/semana_resultados.txt ./resultados/
```

---

## ğŸ› ï¸ Comandos Ãštiles

### GestiÃ³n de HDFS

```bash
# Listar archivos en HDFS
hadoop fs -ls /

# Ver contenido de un archivo
hadoop fs -cat /tmp/2019-Oct.csv | head -10

# Eliminar directorios de output
hadoop fs -rm -r /output/python_*

# Ver espacio usado
hadoop fs -df -h

# Verificar salud del cluster
hdfs dfsadmin -report
```

### GestiÃ³n de Docker

```bash
# Ver logs de un servicio
docker logs namenode
docker logs resourcemanager

# Reiniciar un servicio
docker-compose restart namenode

# Detener todo el cluster
docker-compose down

# Detener y eliminar volÃºmenes (Â¡cuidado!)
docker-compose down -v
```

### Monitoreo de Jobs

```bash
# Ver jobs en ejecuciÃ³n
yarn application -list

# Ver logs de un job
yarn logs -applicationId application_XXXXXXXXXX_XXXX

# Matar un job
yarn application -kill application_XXXXXXXXXX_XXXX
```

---

## ğŸ’¡ Â¿CÃ³mo Funciona MapReduce?

### Paradigma MapReduce

```
Input Data â†’ MAP â†’ Shuffle & Sort â†’ REDUCE â†’ Output
```

1. **Map Phase**: Cada mapper lee lÃ­neas del CSV y emite pares clave-valor
2. **Shuffle & Sort**: Hadoop agrupa automÃ¡ticamente por clave y ordena
3. **Reduce Phase**: Cada reducer recibe todas las claves asignadas y agrega resultados

### Ventajas de Hadoop Streaming con Python

âœ… **No requiere compilaciÃ³n** (a diferencia de Java)  
âœ… **CÃ³digo simple y legible**  
âœ… **FÃ¡cil de debuggear y probar localmente**  
âœ… **Procesamiento distribuido automÃ¡tico**  
âœ… **Escalable a petabytes de datos**  

### Ejemplo: Mapper

```python
#!/usr/bin/env python3
import sys

for line in sys.stdin:  # Lee lÃ­nea por lÃ­nea
    fields = line.strip().split(',')
    product_id = fields[2]
    print(f"{product_id}\t1")  # Emite: clave TAB valor
```

### Ejemplo: Reducer

```python
#!/usr/bin/env python3
import sys
from collections import defaultdict

counts = defaultdict(int)

for line in sys.stdin:  # Recibe datos ordenados por clave
    product_id, count = line.strip().split('\t')
    counts[product_id] += int(count)

# Emitir resultados
for product_id, total in counts.items():
    print(f"{product_id}\t{total}")
```

---

## âš ï¸ Troubleshooting

### Error: "Output directory already exists"

```bash
hadoop fs -rm -r /output/python_top10_productos
```

### Error: "Permission denied"

```bash
chmod +x *.py
```

### Error: "python3: command not found"

Verificar versiÃ³n de Python en el contenedor:
```bash
python --version
python3 --version
```

Si solo existe `python`, cambiar el shebang en los scripts:
```python
#!/usr/bin/env python
```

### El Job se Queda Atascado

```bash
# Ver logs del ResourceManager
docker logs resourcemanager

# Verificar que NodeManager estÃ© activo
docker ps | grep nodemanager

# Reiniciar servicios
docker-compose restart resourcemanager nodemanager
```

### Falta de Memoria

Editar `hadoop.env` y aumentar:
```bash
YARN_CONF_yarn_nodemanager_resource_memory___mb=4096
YARN_CONF_yarn_scheduler_maximum___allocation___mb=2048
```

Luego reiniciar:
```bash
docker-compose down
docker-compose up -d
```

---

## ğŸ“ Estructura del Proyecto

```
hadoop/
â”œâ”€â”€ docker-hadoop/
â”‚   â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n del cluster
â”‚   â”œâ”€â”€ hadoop.env                  # ConfiguraciÃ³n de Hadoop
â”‚   â”œâ”€â”€ README.md                   # Este archivo
â”‚   â”‚
â”‚   â”œâ”€â”€ python-mapreduce/           # Scripts de anÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ README.md               # GuÃ­a detallada MapReduce
â”‚   â”‚   â”œâ”€â”€ run_all.sh              # Script para ejecutar todos los jobs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ top10_mapper.py         # Job 1: Mapper
â”‚   â”‚   â”œâ”€â”€ top10_reducer.py        # Job 1: Reducer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ monto_mapper.py         # Job 2: Mapper
â”‚   â”‚   â”œâ”€â”€ monto_reducer.py        # Job 2: Reducer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ semana_mapper.py        # Job 3: Mapper
â”‚   â”‚   â””â”€â”€ semana_reducer.py       # Job 3: Reducer
â”‚   â”‚
â”‚   â”œâ”€â”€ base/                       # Imagen base de Hadoop
â”‚   â”œâ”€â”€ namenode/                   # NameNode Dockerfile
â”‚   â”œâ”€â”€ datanode/                   # DataNode Dockerfile
â”‚   â”œâ”€â”€ resourcemanager/            # ResourceManager Dockerfile
â”‚   â”œâ”€â”€ nodemanager/                # NodeManager Dockerfile
â”‚   â””â”€â”€ historyserver/              # HistoryServer Dockerfile
```

---

## ğŸ“ˆ Interfaces Web

Una vez que el cluster estÃ© corriendo:

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **NameNode** | http://localhost:9870 | Ver estado del HDFS, archivos, bloques |
| **ResourceManager** | http://localhost:8088 | Monitorear jobs, recursos, logs |
| **HistoryServer** | http://localhost:8188 | Ver historial de jobs completados |

---

## ğŸ” Dataset de E-commerce

### Formato del CSV

```csv
event_time,event_type,product_id,category_id,category_code,brand,price,user_id,user_session
2019-10-01 00:00:00,view,1004767,2053013555631882655,electronics.smartphone,samsung,489.07,520088904,9eb...
2019-10-01 00:00:00,cart,5100500,2053013555631882655,electronics.smartphone,apple,1350.00,513512314,abc...
```

### Tipos de Eventos

- **view**: Usuario visualiza un producto
- **cart**: Usuario aÃ±ade producto al carrito
- **purchase**: Usuario completa la compra

### Columnas Principales

- `event_time`: Timestamp del evento
- `event_type`: Tipo de acciÃ³n del usuario
- `product_id`: ID Ãºnico del producto
- `price`: Precio del producto
- `user_id`: ID Ãºnico del usuario
- `category_code`: CategorÃ­a jerÃ¡rquica (ej: electronics.smartphone)

---

## ğŸ“ Caso de Uso de Negocio

### 1. Top 10 Productos â†’ OptimizaciÃ³n de Inventario

Los productos mÃ¡s vistos indican alta demanda. El negocio puede:
- Aumentar stock de estos productos
- Destacarlos en la pÃ¡gina principal
- Crear campaÃ±as de marketing focalizadas

### 2. Monto por Cliente â†’ SegmentaciÃ³n CLV

Identificar clientes de alto valor permite:
- Programas de fidelizaciÃ³n personalizados
- Ofertas VIP
- Estrategias de retenciÃ³n

### 3. Tendencias Semanales â†’ PlanificaciÃ³n LogÃ­stica

Entender patrones temporales ayuda a:
- Anticipar picos de demanda
- Ajustar recursos de almacÃ©n
- Planificar promociones en semanas de baja actividad

---

## ğŸ¤ Contribuciones

Â¿Mejoras o nuevos anÃ¡lisis? Â¡Pull requests son bienvenidos!

1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/NuevoAnalisis`)
3. Commit tus cambios (`git commit -m 'Agrega anÃ¡lisis de conversiÃ³n'`)
4. Push a la branch (`git push origin feature/NuevoAnalisis`)
5. Abre un Pull Request

---

## ğŸ“š Recursos Adicionales

- [Hadoop Official Documentation](https://hadoop.apache.org/docs/)
- [Hadoop Streaming Guide](https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html)
- [HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [YARN Resource Management](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html)

---

## ğŸ‘¨â€ğŸ’» Autor

**Nicolas Herrera**  
GitHub: [@Nicolas-Lester](https://github.com/Nicolas-Lester)

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para fines educativos.

---

## ğŸ‰ Â¡Empecemos!

```bash
# Clonar y ejecutar
git clone https://github.com/Nicolas-Lester/hadoop.git
cd hadoop/docker-hadoop
docker-compose up -d

# Verificar que todo estÃ¡ corriendo
docker-compose ps

# Â¡Ahora estÃ¡s listo para analizar Big Data! ğŸš€
```

---

**Â¿Preguntas o problemas?** Abre un issue en GitHub o consulta la documentaciÃ³n en `python-mapreduce/README.md`
